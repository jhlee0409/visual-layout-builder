# AI Models Guide - Multi-Model Prompt Generation System

## ê°œìš”

Visual Layout BuilderëŠ” 2025ë…„ 12ì›” ê¸°ì¤€ ìµœì‹  AI ì½”ë”© ëª¨ë¸ë“¤ì„ ì§€ì›í•˜ëŠ” Multi-Model Prompt Generation Systemì„ ì œê³µí•©ë‹ˆë‹¤. ê° AI ëª¨ë¸ì˜ íŠ¹ì„±ì— ë§ê²Œ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ì½”ë“œë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì§€ì› ëª¨ë¸ (35ê°œ)

### Anthropic Claude (5ê°œ)
- **Claude Opus 4.5** â­ ì¶”ì²œ: SWE-bench 80.9%, 2025ë…„ ìµœê°• ì½”ë”© ëª¨ë¸
- **Claude Sonnet 4.5**: í”„ë¡œë•ì…˜ ì½”ë“œ, ê³ í’ˆì§ˆ
- **Claude Sonnet 4**: ê· í˜• ì¡íŒ ì„±ëŠ¥
- **Claude Opus 4**: ìµœê³  í’ˆì§ˆ, ë³µì¡í•œ ì‘ì—…
- **Claude Haiku 3.5**: ë¹ ë¥´ê³  ì €ë ´

### OpenAI GPT (10ê°œ)
- **GPT-5.2** â­ ì¶”ì²œ: SWE-bench 80%, AIME 2025 100%
- **GPT-5**: ê°•ë ¥í•œ ì¶”ë¡ ê³¼ ì½”ë“œ ìƒì„±
- **GPT-5 mini**: ë¹ ë¥´ê³  ì €ë ´í•œ ì¼ë°˜ ì½”ë”©
- **GPT-4.1**: ì°½ì˜ì  ì†”ë£¨ì…˜, ë³µì¡í•œ ì•„í‚¤í…ì²˜
- **GPT-4 Turbo**: ë¹ ë¥¸ ì‘ë‹µ
- **GPT-4**: ì•ˆì •ì  ì„±ëŠ¥
- **o3**: ARC-AGI-2 52.9%, ê¹Šì€ ì¶”ë¡ 
- **o1**: ì¶”ë¡  íŠ¹í™”
- **o1-mini**: ë¹ ë¥¸ ì¶”ë¡ 
- **o3-mini**: ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œ

### Google Gemini (5ê°œ)
- **Gemini 3 Pro** â­ ì¶”ì²œ: LiveCodeBench Elo 2439, SWE-bench 76.2%
- **Gemini 3 Flash**: SWE-bench 78%, ë¹ ë¥´ê³  ì €ë ´
- **Gemini 2.5 Pro**: í”„ë ˆì„ì›Œí¬ íŠ¹í™”, ìµœê³  ê°€ì„±ë¹„
- **Gemini 2.0 Pro**: ëŒ€ìš©ëŸ‰ ì»¨í…ìŠ¤íŠ¸ (2M í† í°)
- **Gemini 2.0 Flash**: ê°€ì¥ ë¹ ë¥´ê³  ì €ë ´

### DeepSeek (3ê°œ)
- **DeepSeek R1** â­ ì¶”ì²œ: ìµœì € ë¹„ìš© (90% ì €ë ´)
- **DeepSeek V3**: ê· í˜• ì¡íŒ ì„±ëŠ¥
- **DeepSeek Coder V2**: ì½”ë”© íŠ¹í™”, 338ê°œ ì–¸ì–´ ì§€ì›

### xAI Grok (4ê°œ)
- **Grok 4.1** â­ ì¶”ì²œ: ì½”ë”© ë²¤ì¹˜ë§ˆí¬ 9.8/10, ì‹¤ì‹œê°„ ë°ì´í„°
- **Grok 4**: ê°•ë ¥í•œ ì¶”ë¡ 
- **Grok 3**: ì¶”ë¡  íŠ¹í™”, ì‹¤ì‹œê°„ ë°ì´í„°
- **Grok 2**: ê· í˜• ì¡íŒ ì„±ëŠ¥

### Meta Llama (3ê°œ) - ì˜¤í”ˆì†ŒìŠ¤
- **Llama 4 Maverick**: ì˜¤í”ˆì†ŒìŠ¤ ì¤‘ ìµœê³  ì„±ëŠ¥
- **Llama 4**: ë¡œì»¬ ì‹¤í–‰ ê°€ëŠ¥, ì»¤ìŠ¤í„°ë§ˆì´ì§•
- **Llama 4 Scout**: ê²½ëŸ‰ ë²„ì „, ì—£ì§€ ë””ë°”ì´ìŠ¤

### Alibaba Qwen (2ê°œ) - ì˜¤í”ˆì†ŒìŠ¤
- **Qwen 2.5 Coder 32B**: ëŒ€í˜• ì½”ë”© íŠ¹í™”
- **Qwen 2.5 Coder**: ë‹¤êµ­ì–´ ì½”ë“œ ì§€ì›

## ë¹ ë¥¸ ì‹œì‘

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•

```typescript
import { createPromptStrategy } from '@/lib/prompt-strategies'
import { sampleSchemas } from '@/lib/sample-data'

// ì „ëµ ìƒì„±
const strategy = createPromptStrategy('claude-opus-4.5')

// í”„ë¡¬í”„íŠ¸ ìƒì„±
const result = strategy.generatePrompt(
  sampleSchemas.github,
  'react',
  'tailwind',
  {
    verbosity: 'detailed',    // 'minimal' | 'normal' | 'detailed'
    chainOfThought: true
  }
)

if (result.success) {
  console.log(result.prompt) // AIì— ë³µë¶™í•  í”„ë¡¬í”„íŠ¸
  console.log(`ì˜ˆìƒ í† í°: ${result.estimatedTokens}`)
}
```

### 2. ëª¨ë¸ ìë™ ì¶”ì²œ

```typescript
import { getModelRecommendations } from '@/lib/prompt-strategies'

// í”„ë¡œì íŠ¸ íŠ¹ì„± ê¸°ë°˜ ì¶”ì²œ
const recommendations = getModelRecommendations({
  schemaComplexity: 'complex',        // simple | medium | complex
  responsiveComplexity: 'medium',     // simple | medium | complex
  needsFrameworkSpecialization: true, // í”„ë ˆì„ì›Œí¬ íŠ¹í™” í•„ìš” ì—¬ë¶€
  costSensitivity: 'medium',          // low | medium | high
  qualityRequirement: 'production',   // draft | production | enterprise
  speedPriority: 'medium'             // low | medium | high
})

// Top 3 ì¶”ì²œ ëª¨ë¸
recommendations.slice(0, 3).forEach((rec, index) => {
  console.log(`${index + 1}. ${rec.modelId}`)
  console.log(`   ì ìˆ˜: ${rec.score}`)
  console.log(`   ë¹„ìš©: ${rec.estimatedCost}`)
  console.log(`   í’ˆì§ˆ: ${rec.estimatedQuality}`)
  console.log(`   ì´ìœ : ${rec.reason}`)
})
```

### 3. ëª¨ë¸ë³„ ì˜µì…˜

```typescript
// Claude Opus 4.5: ìµœê³  í’ˆì§ˆ, Chain-of-Thought
const claudeResult = createPromptStrategy('claude-opus-4.5').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'detailed',       // ìƒì„¸í•œ í”„ë¡¬í”„íŠ¸
    chainOfThought: true,        // ë‹¨ê³„ë³„ ì¶”ë¡  ìš”ì²­
    temperature: 0               // ì‚¬ì‹¤ ê¸°ë°˜ ì‘ì—…
  }
)

// GPT-5.2: ìµœê³  ì„±ëŠ¥, ì°½ì˜ì„±
const gptResult = createPromptStrategy('gpt-5.2').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'normal',          // í‘œì¤€ ìƒì„¸ë„
    includeExamples: true,        // ì˜ˆì‹œ ì½”ë“œ í¬í•¨
    temperature: 0.7              // ì°½ì˜ì  ì‘ì—…
  }
)

// Gemini 3 Pro: í”„ë ˆì„ì›Œí¬ íŠ¹í™”, ìµœì‹  íŒ¨í„´
const geminiResult = createPromptStrategy('gemini-3-pro').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'normal'           // í‘œì¤€ ìƒì„¸ë„
  }
)

// DeepSeek: ë¹„ìš© ìµœì í™”
const deepseekResult = createPromptStrategy('deepseek-r1').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'minimal',         // ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸ (~30% fewer tokens)
    costSensitive: true           // ë¹„ìš© ìµœì í™” ëª¨ë“œ
  }
)

// Llama 4: ì˜¤í”ˆì†ŒìŠ¤, ë¡œì»¬ ì‹¤í–‰
const llamaResult = createPromptStrategy('llama-4-maverick').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'normal'
  }
)
```

## ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

### ì‹œë‚˜ë¦¬ì˜¤ë³„ ì¶”ì²œ

#### 1. í”„ë¡œë•ì…˜ ì½”ë“œ ìƒì„± (í’ˆì§ˆ ìµœìš°ì„ )
```
ì¶”ì²œ: Claude Opus 4.5
ì´ìœ : SWE-bench 80.9%, ìµœê³  í’ˆì§ˆ, ì•ˆì „í•œ ì½”ë“œ
ë¹„ìš©: Premium
ì˜ˆìƒ í† í°: 2,500
```

#### 2. ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… (ì†ë„ + ë¹„ìš©)
```
ì¶”ì²œ: Gemini 3 Flash ë˜ëŠ” DeepSeek R1
ì´ìœ : ë¹ ë¥¸ ì‘ë‹µ, ìµœì € ë¹„ìš©
ë¹„ìš©: Very Low
ì˜ˆìƒ í† í°: 300-500
```

#### 3. í”„ë ˆì„ì›Œí¬ íŠ¹í™” (Next.js, React)
```
ì¶”ì²œ: Gemini 3 Pro
ì´ìœ : LiveCodeBench Elo 2439, í”„ë ˆì„ì›Œí¬ í†µí•© ìµœê°•
ë¹„ìš©: Medium
ì˜ˆìƒ í† í°: 2,300
```

#### 4. ì°½ì˜ì  ì†”ë£¨ì…˜ í•„ìš”
```
ì¶”ì²œ: GPT-5.2
ì´ìœ : AIME 2025 100%, ì°½ì˜ì„± ìµœê³ 
ë¹„ìš©: Premium
ì˜ˆìƒ í† í°: 2,300
```

#### 5. ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œ
```
ì¶”ì²œ: o3 ë˜ëŠ” DeepSeek Coder V2
ì´ìœ : ARC-AGI-2 52.9%, ê¹Šì€ ì¶”ë¡ 
ë¹„ìš©: High-Medium
ì˜ˆìƒ í† í°: 1,300
```

#### 6. ì˜¤í”ˆì†ŒìŠ¤/ë¡œì»¬ ì‹¤í–‰ í•„ìš”
```
ì¶”ì²œ: Llama 4 Maverick ë˜ëŠ” Qwen 2.5 Coder 32B
ì´ìœ : ì˜¤í”ˆì†ŒìŠ¤, ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥
ë¹„ìš©: Very Low (ìì²´ í˜¸ìŠ¤íŒ…)
ì˜ˆìƒ í† í°: 2,000
```

### ë¹„ìš© vs í’ˆì§ˆ ë¹„êµ

| Model | ë¹„ìš© | í’ˆì§ˆ | ì†ë„ | ì¶”ì²œ ìš©ë„ |
|-------|------|------|------|-----------|
| Claude Opus 4.5 | $$$$$ | â­â­â­â­â­ | ëŠë¦¼ | ì—”í„°í”„ë¼ì´ì¦ˆ |
| GPT-5.2 | $$$$ | â­â­â­â­â­ | ì¤‘ê°„ | ë³µì¡í•œ ì¶”ë¡  |
| Claude Sonnet 4.5 | $$$ | â­â­â­â­â­ | ì¤‘ê°„ | í”„ë¡œë•ì…˜ |
| Gemini 3 Pro | $$ | â­â­â­â­ | ë¹ ë¦„ | í”„ë ˆì„ì›Œí¬ íŠ¹í™” |
| Grok 4.1 | $$$ | â­â­â­â­ | ë¹ ë¦„ | ì‹¤ì‹œê°„ ë°ì´í„° |
| DeepSeek R1 | $ | â­â­â­ | ë¹ ë¦„ | ë¹„ìš© ë¯¼ê° |
| Gemini 3 Flash | $ | â­â­â­â­ | ë§¤ìš° ë¹ ë¦„ | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì… |
| Llama 4 Maverick | Free* | â­â­â­â­ | ì¤‘ê°„ | ì˜¤í”ˆì†ŒìŠ¤ |

*ìì²´ í˜¸ìŠ¤íŒ… ì‹œ

### 2025ë…„ 12ì›” ì‹ ê·œ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ

| Model | SWE-bench | íŠ¹í™” ì˜ì—­ | Context |
|-------|-----------|-----------|---------|
| Claude Opus 4.5 | 80.9% | í”„ë¡œë•ì…˜ ì½”ë“œ | 200K |
| GPT-5.2 | 80% | ìˆ˜í•™ì  ì¶”ë¡  | 256K |
| Gemini 3 Pro | 76.2% | í”„ë ˆì„ì›Œí¬ | 2M |
| Gemini 3 Flash | 78% | ì†ë„ | 1M |
| o3 | - | ARC-AGI-2 52.9% | 200K |
| Grok 4.1 | - | ì‹¤ì‹œê°„ 9.8/10 | 256K |

## ê³ ê¸‰ ì‚¬ìš©ë²•

### 1. ì¹´í…Œê³ ë¦¬ë³„ ëª¨ë¸ ëª©ë¡

```typescript
import { getModelsByCategory } from '@/lib/prompt-strategies'

const modelsByCategory = getModelsByCategory()

console.log('Anthropic:', modelsByCategory.anthropic)
// ['claude-opus-4.5', 'claude-sonnet-4.5', 'claude-sonnet-4', 'claude-opus-4', 'claude-haiku-3.5']

console.log('Google:', modelsByCategory.google)
// ['gemini-3-pro', 'gemini-3-flash', 'gemini-2.5-pro', 'gemini-2.0-pro', 'gemini-2.0-flash']

console.log('Meta:', modelsByCategory.meta)
// ['llama-4', 'llama-4-scout', 'llama-4-maverick']

console.log('Alibaba:', modelsByCategory.alibaba)
// ['qwen-2.5-coder', 'qwen-2.5-coder-32b']
```

### 2. ëª¨ë¸ ë©”íƒ€ë°ì´í„° ì¡°íšŒ

```typescript
import { getModelMetadata } from '@/lib/ai-model-registry'

const metadata = getModelMetadata('claude-opus-4.5')

console.log('Name:', metadata.name)
console.log('Provider:', metadata.provider)
console.log('Best for:', metadata.bestFor)
console.log('Capabilities:', metadata.capabilities)
console.log('Cost:', metadata.cost)
console.log('Performance:', metadata.performance)
```

### 3. ë³µì¡ë„ ìë™ ê³„ì‚°

```typescript
import { calculateSchemaComplexity, calculateResponsiveComplexity } from '@/lib/ai-model-registry'

const schemaComplexity = calculateSchemaComplexity(schema.components.length)
// 'simple' (â‰¤3), 'medium' (4-8), 'complex' (9+)

const responsiveComplexity = calculateResponsiveComplexity(
  schema.breakpoints.length,
  schema.components.filter(c => c.responsive).length
)
// 'simple', 'medium', 'complex'
```

### 4. Factory ìºì‹± ê´€ë¦¬

```typescript
import { strategyFactory } from '@/lib/prompt-strategies'

// ìºì‹œ í¬ê¸° í™•ì¸
console.log('Cache size:', strategyFactory.getCacheSize())

// ìºì‹œ ì´ˆê¸°í™” (ë©”ëª¨ë¦¬ ê´€ë¦¬)
strategyFactory.clearCache()
```

## ìµœì í™” íŒ

### 1. ë¹„ìš© ìµœì í™”

```typescript
// DeepSeek ì‚¬ìš© + ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸
const result = createPromptStrategy('deepseek-r1').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'minimal',         // ~30% fewer tokens
    costSensitive: true
  }
)
// ì˜ˆìƒ ë¹„ìš©: Claude ëŒ€ë¹„ 90% ì ˆê°
```

### 2. í’ˆì§ˆ ìµœì í™”

```typescript
// Claude Opus 4.5 ì‚¬ìš© + ìƒì„¸ ì§€ì¹¨ + CoT
const result = createPromptStrategy('claude-opus-4.5').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'detailed',        // ~40% more tokens, clearer instructions
    chainOfThought: true,
    temperature: 0
  }
)
// ìµœê³  í’ˆì§ˆ í”„ë¡œë•ì…˜ ì½”ë“œ
```

### 3. ì†ë„ ìµœì í™”

```typescript
// Gemini 3 Flash ì‚¬ìš© + ê°„ê²°í•œ í”„ë¡¬í”„íŠ¸
const result = createPromptStrategy('gemini-3-flash').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'minimal'          // ~30% fewer tokens, faster processing
  }
)
// ê°€ì¥ ë¹ ë¥¸ ì‘ë‹µ (< 1ì´ˆ)
```

### 4. ì˜¤í”ˆì†ŒìŠ¤ í™œìš©

```typescript
// Llama 4 ë˜ëŠ” Qwen ì‚¬ìš© - ìì²´ í˜¸ìŠ¤íŒ… ì‹œ ë¬´ë£Œ
const result = createPromptStrategy('llama-4-maverick').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'normal'
  }
)
// ë¹„ìš©: $0 (ìì²´ ì¸í”„ë¼ ë¹„ìš©ë§Œ)
```

## Best Practices

### 1. í”„ë¡œì íŠ¸ ì´ˆê¸° ë‹¨ê³„
- **ì¶”ì²œ ëª¨ë¸**: Gemini 3 Flash, DeepSeek R1
- **ì´ìœ **: ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…, ë¹„ìš© ì ˆê°
- **ì„¤ì •**: `verbosity: 'minimal'`, `costSensitive: true`

### 2. í”„ë¡œë•ì…˜ ê°œë°œ ë‹¨ê³„
- **ì¶”ì²œ ëª¨ë¸**: Claude Opus 4.5, Gemini 3 Pro
- **ì´ìœ **: ê³ í’ˆì§ˆ ì½”ë“œ, í”„ë ˆì„ì›Œí¬ íŠ¹í™”
- **ì„¤ì •**: `verbosity: 'detailed'` (ìƒì„¸í•œ ì§€ì¹¨ìœ¼ë¡œ í’ˆì§ˆ í–¥ìƒ)

### 3. ë³µì¡í•œ ì•„í‚¤í…ì²˜ ì„¤ê³„
- **ì¶”ì²œ ëª¨ë¸**: GPT-5.2, Claude Opus 4.5
- **ì´ìœ **: ì°½ì˜ì  ì†”ë£¨ì…˜, ë³µì¡í•œ íŒ¨í„´
- **ì„¤ì •**: `temperature: 0.7-0.9`, `chainOfThought: true`

### 4. í”„ë ˆì„ì›Œí¬ íŠ¹í™” ì‘ì—…
- **ì¶”ì²œ ëª¨ë¸**: Gemini 3 Pro
- **ì´ìœ **: LiveCodeBench Elo 2439, ìµœì‹  íŒ¨í„´
- **ì„¤ì •**: `verbosity: 'normal'`

### 5. ì˜¤í”ˆì†ŒìŠ¤ ìš”êµ¬ì‚¬í•­
- **ì¶”ì²œ ëª¨ë¸**: Llama 4 Maverick, Qwen 2.5 Coder 32B
- **ì´ìœ **: ë¡œì»¬ ì‹¤í–‰, ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥
- **ì„¤ì •**: `verbosity: 'normal'`

## ë¬¸ì œ í•´ê²°

### Q: í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¸´ ê²½ìš°
```typescript
// verbosityë¥¼ 'minimal'ë¡œ ë³€ê²½
const result = strategy.generatePrompt(schema, 'react', 'tailwind', {
  verbosity: 'minimal'
})
```

### Q: ë¹„ìš©ì´ ë„ˆë¬´ ë†’ì€ ê²½ìš°
```typescript
// DeepSeek ì‚¬ìš© + costSensitive ëª¨ë“œ
const result = createPromptStrategy('deepseek-r1').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    costSensitive: true,
    verbosity: 'minimal'
  }
)
```

### Q: ì½”ë“œ í’ˆì§ˆì´ ë‚®ì€ ê²½ìš°
```typescript
// Claude Opus 4.5 ì‚¬ìš© + ìƒì„¸ í”„ë¡¬í”„íŠ¸
const result = createPromptStrategy('claude-opus-4.5').generatePrompt(
  schema,
  'react',
  'tailwind',
  {
    verbosity: 'detailed',        // ìƒì„¸í•œ ì§€ì¹¨ ì œê³µ
    chainOfThought: true
  }
)
```

### Q: ì–´ë–¤ ëª¨ë¸ì„ ì„ íƒí•´ì•¼ í• ì§€ ëª¨ë¥´ëŠ” ê²½ìš°
```typescript
// ìë™ ì¶”ì²œ ì‹œìŠ¤í…œ ì‚¬ìš©
const recommendations = getModelRecommendations({
  schemaComplexity: 'medium',
  responsiveComplexity: 'medium',
  needsFrameworkSpecialization: true,
  costSensitivity: 'medium',
  qualityRequirement: 'production',
  speedPriority: 'medium'
})

const bestModel = recommendations[0]
const strategy = createPromptStrategy(bestModel.modelId)
```

## í…ŒìŠ¤íŠ¸

ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:

```bash
npx tsx scripts/test-ai-model-strategies.ts
```

**ì˜ˆìƒ ê²°ê³¼:**
- âœ… Factory ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸
- âœ… ëª¨ë¸ ì¶”ì²œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
- âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
- âœ… í”„ë¡¬í”„íŠ¸ ì°¨ì´ì  ë¹„êµ í…ŒìŠ¤íŠ¸

Success Rate: 100% ğŸ‰

## ì°¸ê³  ìë£Œ

### ë°ì´í„° ì¶œì²˜
- SWE-bench Verified Leaderboard (2025-12)
- Aider Polyglot Coding Benchmark (2025-12)
- LiveCodeBench Elo Rankings (2025-12)
- ARC-AGI-2 Benchmark (2025-12)
- AIME 2025 Math Competition (2025-12)
- Render.com AI Coding Agents Benchmark (2025)

### ê´€ë ¨ íŒŒì¼
- `types/ai-models.ts`: íƒ€ì… ì •ì˜
- `lib/ai-model-registry.ts`: ëª¨ë¸ ë©”íƒ€ë°ì´í„°
- `lib/prompt-strategies/`: ì „ëµ êµ¬í˜„
- `scripts/test-ai-model-strategies.ts`: í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

## ë¼ì´ì„¼ìŠ¤

MIT License

## ê¸°ì—¬

ìƒˆë¡œìš´ AI ëª¨ë¸ ì¶”ê°€ ë°©ë²•:

1. `types/ai-models.ts`ì— ëª¨ë¸ ID ì¶”ê°€
2. `lib/ai-model-registry.ts`ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
3. `lib/prompt-strategies/`ì— ìƒˆë¡œìš´ ì „ëµ í´ë˜ìŠ¤ ìƒì„± (ë˜ëŠ” ê¸°ì¡´ ì „ëµ ì‚¬ìš©)
4. `lib/prompt-strategies/strategy-factory.ts`ì— provider ë§¤í•‘
5. í…ŒìŠ¤íŠ¸ ì‘ì„± ë° ê²€ì¦

---

**Last Updated:** 2025-12-27
**Version:** 2.0.0
**Status:** Production Ready âœ…
